{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_UNET.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python (cs230)",
      "language": "python",
      "name": "cs230"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8B6ES4v95gk",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/tdrobbins/unet.git@nchannels\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dqlHpp5i3CgF",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import unet\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as pp\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e4_XrGAfAsh5"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JzlN5zwYaTKB",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/cs230/')\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBCHx4Ox8irk",
        "colab": {}
      },
      "source": [
        "# Loading and preprocessing data\n",
        "\n",
        "# Preprocessing paramters\n",
        "CROP        = 512    # split raw images into many CROPxCROP images\n",
        "RESIZE      = 128    # downsample cropped image to RESIZExRESIZE\n",
        "N_CLASSES   = 5      # 2, 5, or 10\n",
        "CELLTOWERS  = True  \n",
        "\n",
        "STATE = \"*\"\n",
        "\n",
        "# Loading satellite images into an array\n",
        "sat_files = np.sort(glob(\"./drive/My Drive/cs230/sentinel2/{}/*.tif\".format(STATE)))\n",
        "cell_files = np.sort(glob(\"./drive/My Drive/cs230/celltowers/{}/*.jpg\".format(STATE)))\n",
        "\n",
        "X = utils.load_sat_imgs(sat_files, cell_files, crop_size=CROP, resize=RESIZE)  \n",
        "m,nx,ny,nchannels = X.shape\n",
        "\n",
        "# Loading nclasses version of lte mask images into an array\n",
        "lte_files = np.sort(glob(\"./drive/My Drive/cs230/lte/{}/*.jpg\".format(STATE,N_CLASSES)))\n",
        "Y = utils.load_masks(lte_files, N_CLASSES, crop_size==CROP, resize=RESIZE, onehot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6UZSVBY4A-Cq"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuuwPTTGVjyQ",
        "colab": {}
      },
      "source": [
        "# Setting up the datasets for tf\n",
        "TRAIN_SPLIT   = 0.8\n",
        "BATCH_SIZE    = 32\n",
        "CLASS_WEIGHTS = \"auto\" # make sure len(CLASS_WEIGHTS) == N_CLASSES\n",
        "SEED          = 1\n",
        "\n",
        "# Experimenting with settings CLASS_WEIGHTS automatically\n",
        "if CLASS_WEIGHTS == \"auto\":\n",
        "    counts = Y.sum(axis=tuple(range(Y.ndim - 1)))\n",
        "    CLASS_WEIGHTS = np.round(max(counts)/counts).astype(np.uint)\n",
        "\n",
        "if CLASS_WEIGHTS is not None:\n",
        "    Y = Y*CLASS_WEIGHTS\n",
        "    \n",
        "(X_train, Y_train), (X_dev, Y_dev) = utils.split_train_dev(X,Y,split=TRAIN_SPLIT, batch_size=BATCH_SIZE, seed=SEED)\n",
        "\n",
        "# Create generators using split datasets\n",
        "train_datagen = ImageDataGenerator()\n",
        "dev_datagen = ImageDataGenerator()\n",
        "\n",
        "train_set = train_datagen.flow(X_train,Y_train,batch_size=BATCH_SIZE)\n",
        "dev_set = dev_datagen.flow(X_dev,Y_dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjNOWqO-4aKh",
        "colab": {}
      },
      "source": [
        "# Model parameters\n",
        "LEARNING_RATE = 0.0001\n",
        "LAYER_DEPTH   = 5\n",
        "ROOT_FILTERS  = 64\n",
        "DROPOUT       = 0.0\n",
        "\n",
        "SAVE_ROOT = \"/content/drive/My Drive/cs230/logs/\"\n",
        "\n",
        "SAVE_PATH = SAVE_ROOT+datetime.datetime.now().strftime(\"%y%m%d-%H%M\")\n",
        "\n",
        "# Building the model\n",
        "unet_model = unet.build_model(nx, ny,\n",
        "                          channels = nchannels,\n",
        "                          num_classes = N_CLASSES,\n",
        "                          layer_depth = LAYER_DEPTH,\n",
        "                          filters_root= ROOT_FILTERS,\n",
        "                          dropout_rate = DROPOUT,\n",
        "                          padding = \"same\"\n",
        "                          )\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=SAVE_PATH, histogram_freq=1)\n",
        "\n",
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"Precision\", \"Recall\", \"CategoricalAccuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BYQbd8UdnRsM",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir \"$SAVE_ROOT\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xb5p-zV6EukX",
        "colab": {}
      },
      "source": [
        "# Training parameters \n",
        "EPOCHS_PER_LOOP = 100\n",
        "LOOPS           = 15\n",
        "\n",
        "for i in range(LOOPS):\n",
        "  model_history = unet_model.fit(train_set,\n",
        "                                validation_data=dev_set,\n",
        "                                epochs=EPOCHS_PER_LOOP, \n",
        "                                batch_size=BATCH_SIZE,\n",
        "                                steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "                                initial_epoch=i*EPOCHS_PER_LOOP,\n",
        "                                callbacks=[tensorboard_callback])\n",
        "  unet_model.save(SAVE_PATH+\"model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w588h5o9uyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}